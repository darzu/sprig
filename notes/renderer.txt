WebGL
  https://twgljs.org // tiny layer over webgl
  https://twgljs.org/examples/twgl-cube.html
  https://twgljs.org/examples/webgl-cube.html
  https://github.com/pmndrs/react-three-fiber
  https://enable3d.io (three.js, ammo.js, capacitor.js, phaser, )
  https://github.com/tamani-coding/enable3d-physics-examples

Three.js:
  https://threejs.org
  https://www.npmtrends.com/babylonjs-vs-three


WebGL learning:
  https://games.greggman.com/game/webgl-3d-cameras/
  https://webglfundamentals.org/webgl/lessons/webgl-3d-camera.html
  https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/WebGL_best_practices
  https://www.tutorialspoint.com/webgl/webgl_interactive_cube.htm

Babylon:
  https://www.babylonjs.com
  https://playground.babylonjs.com
  https://nme.babylonjs.com // material editor (flow based)
  https://github.com/BabylonJS/SummerFestival
  https://doc.babylonjs.com/guidedLearning/createAGame
  https://babylonjs.medium.com/from-unity-to-babylon-js-how-is-the-journey-c71f79482aa3
  https://news.ycombinator.com/from?site=babylonjs.com

Three.js tutorial:
  https://www.youtube.com/watch?v=cp-H_6VODko

HAXE:
  http://babylonhx.com
  https://haxe.org/use-cases/games/
    Northgard, Dead Cells, "Papers, Please", Rymdkapsel
  https://github.com/armory3d

  Heaps.io:
    https://heaps.io

Multi-platform:
  https://github.com/expo/expo/tree/master/packages/expo-gl#expo-gl

PlayCanvas:
  https://playcanvas.com
  praise: https://news.ycombinator.com/item?id=27050731
  https://news.ycombinator.com/from?site=playcanvas.com
  https://blog.playcanvas.com/a-multiplayer-3rd-person-shooter-in-html5/

Unity Tiny:
  https://unity.com/solutions/instant-games
  https://forum.unity.com/threads/project-tiny-0-32-preview-is-available-ui-new-skinned-mesh-renderer-blendshape-sample.1045204/
  https://tiny.vision/demos/Tiny3D/Wasm/Tiny3D.html (needs Chrome or Safari Preview)
  https://github.com/Unity-Technologies/ProjectTinySamples/tree/master/Tiny3D
  (OLD!) https://docs.unity3d.com/Packages/com.unity.tiny@0.13/manual/scripting-systems.html
  (OLD!) https://docs.unity3d.com/Packages/com.unity.tiny@0.13/manual/intro-for-unity-developers.html

Pict3D:
  https://docs.racket-lang.org/pict3d/index.html

Regl:
  https://github.com/regl-project/regl

e.g.
  https://github.com/jacklaplante/bowdown
  https://github.com/onegeek/webglu

Sketch fab:
  https://sketchfab.com

Defold:
  https://defold.com
    "I recall our unity engineer quite liked Defold, which had an 
    integrated builder tool, but for some reason the lead dev didnâ€™t 
    want to go with it." - https://news.ycombinator.com/item?id=24018097
  https://github.com/defold/defold
  Owned by King (Candy Crush, etc)

Google Docs switching to canvas:
  https://workspaceupdates.googleblog.com/2021/05/Google-Docs-Canvas-Based-Rendering-Update.html

Flutter does all UI via canvas:
  https://gallery.flutter.dev/#/

Construct:
  https://www.construct.net/en/make-games/showcase

WebGPU
    https://github.com/gpuweb/gpuweb
    status:
        https://github.com/gpuweb/gpuweb/wiki/Implementation-Status
    spec:
        https://gpuweb.github.io/gpuweb/
    examples:
      https://www.willusher.io/projects#WebGPU%20Experiments

Construct blog:
  https://www.construct.net/en/blogs/ashleys-blog-2/brief-history-graphics-web-1517
  https://www.construct.net/en/blogs/ashleys-blog-2/webgl-webgpu-construct-1519

Safari WebGPU intro:
  https://webkit.org/blog/9528/webgpu-and-wsl-in-safari/

Mozilla WebGPU intro:
  https://hacks.mozilla.org/2020/04/experimental-webgpu-in-firefox/

Chrome WebGPU intro:
  https://www.youtube.com/watch?v=K2JzIUIHIhc
  
TO DECIDE:
    Build our own renderer?

Understand URP:
    https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@12.0/manual/universalrp-builtin-feature-comparison.html'

GLTF viewers:
    https://sandbox.babylonjs.com/
    https://gltf-viewer.donmccurdy.com/
    https://gltf.insimo.com/
    https://github.khronos.org/glTF-Sample-Viewer-Release/
        https://github.com/KhronosGroup/glTF-Sample-Viewer

GLTF loader:
    https://github.com/mrdoob/three.js/blob/a98b9bf/examples/js/loaders/GLTFLoader.js

GLTF compression:
    https://google.github.io/draco/
        has JS encode / decode libraries

WebGPU on Chrome:
    https://developers.google.com/web/updates/2019/08/get-started-with-gpu-compute-on-the-web

WebGPU tutorials:
    https://alain.xyz/blog/raw-webgpu
        matrix library: https://github.com/toji/gl-matrix
    https://www.willusher.io/graphics/2020/06/15/0-to-gltf-triangle

WebGPU samples:
    https://github.com/mikbry/awesome-webgpu
    http://austin-eng.com/webgpu-samples/samples/computeBoids

Vulkan vs OpenGL:
    https://gamedev.stackexchange.com/questions/96014/what-is-vulkan-and-how-does-it-differ-from-opengl

WebGPU uses Web Shading Language (WSL)

webgpu-rs:
    https://github.com/gfx-rs/wgpu-rs
    Why WebGPU for native is good:
      http://kvark.github.io/web/gpu/native/2020/05/03/point-of-webgpu-native.html
    https://dawn.googlesource.com/dawn (webgpu on native by Google)

MIT computer graphics lectures:
    https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-837-computer-graphics-fall-2012/lecture-notes/
    lectures
      https://www.youtube.com/watch?v=-LqUu61oRdk&list=PLQ3UicqQtfNuBjzJ-KEWmG1yjiRMXYKhh
      https://www.youtube.com/watch?v=t7g2oaNs-c8&list=PLQ3UicqQtfNuKZjdA3fY1_X9gXn13JLlW

Game Engine Architecture book:
    https://www.gameenginebook.com/

RTX / ray tracing:
  minecraft RTX: https://alain.xyz/blog/frame-analysis-minecraftrtx
  on m1 https://www.willusher.io/graphics/2020/12/20/rt-dive-m1
    ~7-9 million rays / sec
  beyond ray-tracing http://sci.utah.edu/~will/papers/rtx-points-hpg19.pdf
  on GPU via Cuda: https://developer.nvidia.com/blog/accelerated-ray-tracing-cuda/
  Ray Tracing Gems II:
    http://www.realtimerendering.com/raytracinggems/rtg2/index.html

pbr / physically based rendering:
  https://pbrt.org
  https://www.pbr-book.org/3ed-2018/contents

GPU API concepts compared:
  https://alain.xyz/blog/comparison-of-modern-graphics-apis

Defered rendering:
  https://gamedev.stackexchange.com/questions/74/what-is-deferred-rendering
    Forward: O(geometry * lights)
    Defered: O(geometry + lights)
  Works poorly for transparency (most engines use Forward)
    see: depth peeling
  Uses large amounts of VRAM and frame buffer bandwidth
  stencil-based geometry vs "tiled/froxel compute-based shading"
  Unity: https://docs.unity3d.com/2021.2/Documentation/Manual/RenderTech-DeferredShading.html
  https://www.reddit.com/r/gamedev/comments/8klygv/is_deferred_shading_still_considered_state_of_the/
    "It looks like the industry is going towards a forward+/hybrid approach"
      0. Render Depth Prepass (optional, could prepare a thin gbuffer on this pass)
      1. Use depth buffer (or not) to bin lights into screenspace tiles, save this as a light buffer
      2. Render the geometry with the full shader, and get the light information from the screenspace coordinate, wich lets you see the lights on that tile
      3. Postprocess.
    "Forward+ splits the screen into a 2d grid and a process (compute or other shader) figures out what lights affect that tile. Forward++ takes this a step 
    further and instead of a 2d grid splitting the screen, its a 3d grid splitting space with perspective."
  used by Horizon Zero Dawn

Shadows:
  Shadow volumes? (aka stencil shadows)
    https://en.wikipedia.org/wiki/Shadow_volume
  Shadow mapping
    https://www.youtube.com/watch?v=o6zDfDkOFIc
    use the normal view frustum to compute the bounding box that should be used for the shadow map
      compute view frustum with different far-clipping plane to adjust shadow distance

Lighting:
  pixel vs vertex
    could subdivide large triangles so vertex lighting is more accurate; no storage cost
    vertex + tessellation for particles (e.g. smoke):
      http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.699.187&rep=rep1&type=pdf
  Spherical Harmonics lighting
    https://computergraphics.stackexchange.com/questions/4164/what-are-spherical-harmonics-light-probes
    https://mynameismjp.wordpress.com/2016/10/09/sg-series-part-1-a-brief-and-incomplete-history-of-baked-lighting-representations/
  deferred vs forward
  https://www.scratchapixel.com/lessons/3d-basic-rendering/introduction-to-shading/shading-normals
  WebGPU "clustered forward shading"
    https://toji.github.io/webgpu-clustered-shading/
    https://github.com/toji/webgpu-clustered-shading
      "I don't think WGSL has atomic methods yet so I can't effectively do the light list compacting 
      the way I want (or at least I don't know the workaround)."

TO LEARN:
  Fourier transform
    then Spherical Harmonics

GPU perf for artists:
  http://www.fragmentbuffer.com/gpu-performance-for-game-artists/
    https://news.ycombinator.com/item?id=14726355
    https://news.ycombinator.com/item?id=21978146

Frame analysis:
  compilation:
    http://www.adriancourreges.com/blog/
  RenderDoc:
    https://renderdoc.org
    https://spector.babylonjs.com (for WebGL)
  https://zhangdoa.com/posts/rendering-analysis-cyberpunk-2077
  https://alain.xyz/blog/frame-analysis-overwatch
  https://alain.xyz/blog/frame-analysis-mk11
  https://alain.xyz/blog/frame-analysis-minecraftrtx
  https://aschrein.github.io/2019/08/11/metro_breakdown.html
  https://aschrein.github.io/2019/08/01/re2_breakdown.html
  http://www.adriancourreges.com/blog/2016/09/09/doom-2016-graphics-study/
    https://news.ycombinator.com/item?id=12461896
    http://advances.realtimerendering.com/s2016/Siggraph2016_idTech6.pdf
  http://www.adriancourreges.com/blog/2017/12/15/mgs-v-graphics-study/
  http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/
    https://news.ycombinator.com/item?id=10492876
  http://www.adriancourreges.com/blog/2015/06/23/supreme-commander-graphics-study/
    https://news.ycombinator.com/item?id=9770020
  http://www.adriancourreges.com/blog/2015/03/10/deus-ex-human-revolution-graphics-study/
    https://news.ycombinator.com/item?id=9565891

BLOGS TO SCAN:
  https://www.ea.com/frostbite/news
  http://advances.realtimerendering.com/s2015/index.html (siggraph conference)
  https://simonschreibt.de/game-art-tricks/
  https://www.willusher.io
    lots of graphics projects: https://www.willusher.io/projects
    teapot rendering challenge https://graphics.cs.utah.edu/trc/
  https://www.cs.washington.edu/research/graphics
    https://grail.cs.washington.edu/research/
    http://courses.cs.washington.edu/courses/cse457/ Computer Graphics
    http://courses.cs.washington.edu/courses/cse458/ Computer Animation
    http://courses.cs.washington.edu/courses/csep557/ Trends in Computer Graphics
    http://courses.cs.washington.edu/courses/cse557/ Computer Graphics
  http://madebyevan.com

coloring models:
  https://www.willusher.io/webgl-ewa-splatter/#Dinosaur

TO READ:
  https://forum.beyond3d.com/threads/gpu-driven-rendering-siggraph-2015-follow-up.57240/
    "about GPU-driven rendering pipelines"

GDC:
  Horizon Zero Dawn:
    Vegitation https://www.youtube.com/watch?v=wavnKZNSYqU
    game design https://www.youtube.com/watch?v=TawhcWao9ls
    procedural gen https://www.youtube.com/watch?v=ToCozpl1sYY

Rust -> WebGPU examples:
  https://github.com/gfx-rs/wgpu-rs/tree/master/examples
  https://wgpu.rs

"Mixed resolution rendering":
  https://www.gdcvault.com/play/1022982/Mixed-Resolution-Rendering-in-Skylanders
    for clouds based on sprites
    downsample depth -> raster -> "bilateral" upsample 

LOD / automatic mesh simplification:
  quad simplification: https://www.youtube.com/watch?v=vBJcdClynFE

Rendering pipeline:
  https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview

hierarchical /  models:
  https://sites.google.com/site/csc8820/educational/how-to-animate-hierarchical-models
  https://canvas.dartmouth.edu/courses/16840/assignments/82764

how many triangles?
  "overwatch ingame characters has 60K tris"

"bundles"?
  https://computergraphics.stackexchange.com/questions/4066/whats-the-main-difference-of-pipeline-process-between-vulkan-and-dx12

Why r draw calls expensive?
  "because if you send too little to the GPU, you're CPU bound and the GPU idles"
  https://stackoverflow.com/questions/4853856/why-are-draw-calls-expensive
  https://www.nvidia.com/docs/IO/8228/BatchBatchBatch.pdf

Data per triangle:
  "instanced vertex attributes"
  gl_PrimitiveID
  "texture buffer object (TBO)" for high primitive count
    texelFetch

Graphics storage options:
  Vertex buffer
  Vertex buffer (instance step)
  Uniform buffer
    Small, performant
  SSBOS
    large, slow, writable

Unreal 5 analysis:
  https://www.elopezr.com/a-macro-view-of-nanite/

Camera transformations:
  https://www.3dgep.com/understanding-the-view-matrix/#Transformations
  http://www.codinglabs.net/article_world_view_projection_matrix.aspx
  https://gamedev.stackexchange.com/questions/178643/the-view-matrix-finally-explained
  https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix
  http://web.cse.ohio-state.edu/~wang.3602/courses/cse5542-2013-spring/6-Transformation_II.pdf
  https://learnopengl.com/Getting-started/Coordinate-Systems

hierarchical modeling:
  https://www.youtube.com/watch?v=JdhpViedm0g&list=PLQ3UicqQtfNuBjzJ-KEWmG1yjiRMXYKhh&index=5

Low-poly planet map effect:
  https://www.youtube.com/watch?v=i5zwDoYXH5c

WebGPU vs WebGL:
  https://www.babylonjs.com/demos/webgpu/forestwebgl
  https://www.babylonjs.com/demos/webgpu/forestwebgpu

Alpha tested vs transparency:
  https://forum.unity.com/threads/difference-between-alphatest-and-transparent-renderqueue.458750/
  alpha tested renders front-to-back (occluded pixels r ignored)
  transparency renders back-to-front

transparency:
  http://learnwebgl.brown37.net/11_advanced_rendering/alpha_blending.html
    in the standard technique, u have to order transparent objects back to front and
      render them in a seperate pass
    b/c alpha blending is not commutitive in real life; 
      a 99% opaque object in front will dominate the result color
    unless: 
      only one transparent object; 
      transparent objects never overlap in the camera;
    use insertion sort b/c less work when nothing changes frame to frame

Texture compression:
  BC7, BC4, BCn
  https://www.reedbeta.com/blog/understanding-bcn-texture-compression-formats/

Foveated rendering:
  https://en.wikipedia.org/wiki/Foveated_rendering

GPU hardware:
  Rasterization is still done in fixed hardware, not programmable
    https://en.wikipedia.org/wiki/Rasterisation
    (Intel tried with Larrabee, aborted)
    (Nvidia tried: https://highperformancegraphics.net/previous/www_2011/media/Papers/HPG2011_Papers_Laine.pdf, 
      https://dl.acm.org/doi/10.1145/2018323.2018337, http://code.google.com/p/cudaraster/)
      Issues: interpolation, anti-aliasing, power consumption
    Desire for software rasterization:
      shader perf boost?
      ROP (render output unit): a-buffering, order-independent transparency
      Stochastic rasterization
      Non-linear rasterization
  Vertex and fragment shaders
  Compute vs Fragment for post-processing:
    https://computergraphics.stackexchange.com/questions/54/when-is-a-compute-shader-more-efficient-than-a-pixel-shader-for-image-filtering
  ROP:
    https://en.wikipedia.org/wiki/Render_output_unit
    handles anti-aliasing (e.g. MSAA)

Z-order curve:
  https://en.wikipedia.org/wiki/Z-order_curve#Applications
  Zig-zag textures for more efficient cache locality

Albedo vs Diffuse:
  https://computergraphics.stackexchange.com/questions/350/albedo-vs-diffuse

Virtual texturing:
  http://holger.dammertz.org/stuff/notes_VirtualTexturing.html
  https://computergraphics.stackexchange.com/questions/1768/how-can-virtual-texturing-actually-be-efficient

Don't have T junctions in meshes:
  https://computergraphics.stackexchange.com/questions/1461/why-do-t-junctions-in-meshes-result-in-cracks

Frustum culling:
  https://www.iquilezles.org/www/articles/frustumcorrect/frustumcorrect.htm

ALTERNATE APPROACH:
  It could be worth considering going for a low-res ray tracing. E.g. maybe just 256x256 pixels, but 
  ray tracing them all.
  This would let us drastically simplify the renderer and do the cool RTX techniques
  Using SDF tech, we could get some very cool meshes and mesh building

SDF for text:
  https://www.youtube.com/watch?v=1b5hIMqz_wM
    Material Maker

VFX explosions:
  https://www.youtube.com/watch?v=dDsb_9n-Gik

Flow maps and gradient maps for moving textures:
  https://www.youtube.com/watch?v=KfphtLRoUB0

Outlines:
  Jump flooding
  https://bgolus.medium.com/the-quest-for-very-wide-outlines-ba82ed442cd9
  https://prideout.net/blog/distance_fields/
  https://blog.demofox.org/2016/02/29/fast-voronoi-diagrams-and-distance-dield-textures-on-the-gpu-with-the-jump-flooding-algorithm/
  https://shaderbits.com/blog/various-distance-field-generation-techniques
  
  overwatch and control use "sobol" for outlines?
    https://www.youtube.com/watch?v=hxPQ2F96F9E
    looks like a sampling technique:
      https://www.pbr-book.org/3ed-2018/Sampling_and_Reconstruction/Sobol_Sampler

Mesh simplification:
  https://www.simplygon.com
  techniques: billboard cloud, flip book

Noise is good in game art?:
  makes things less flat
  https://simblob.blogspot.com/2009/06/noise-in-game-art.html

Factory Station's rendering:
  https://twitter.com/GravitonPunch/status/1453072441316675584
  https://twitter.com/alexanderameye/status/1375463146446585857

Rendering problem cheat sheet:
  https://techartaid.com/cheatsheet/

To improve look and feel, I should write a .gltf exporter than load that in Unity 
  or blender and play with materials, lighting, shaders etc until it looks how I want.
  Then figure out what the delta is and how to impl it. Probably cut corners.

Waves:
  https://playground.babylonjs.com/?webgpu#YX6IB8#55
  https://github.com/gasgiant/FFT-Ocean